{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a281fa-d5b7-4d2a-8797-929c3ea86efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "# ---------------------Configuration----------------------------\n",
    "\n",
    "DATA_DIR = Path(\"xxxxxx\")  # adjust if needed\n",
    "\n",
    "# Facility sizes and constraints for NEW builds\n",
    "# Each has max 0-5 capacity equal to half the total capacity\n",
    "NEW_FACILITY_SIZES = {\n",
    "    \"small\":  {\"total\": 100, \"max_0_5\": 50,  \"cost\": 65000},\n",
    "    \"medium\": {\"total\": 200, \"max_0_5\": 100, \"cost\": 95000},\n",
    "    \"large\":  {\"total\": 400, \"max_0_5\": 200, \"cost\": 115000},\n",
    "}\n",
    "\n",
    "# Special equipment cost per new slot for ages 0–5\n",
    "NEW_EQUIP_COST_PER_0_5 = 100.0\n",
    "\n",
    "# Distance threshold in miles (Realistic model)\n",
    "MIN_DISTANCE_MILES = 0.06\n",
    "\n",
    "# Employment & income thresholds for \"high-demand\"\n",
    "EMPLOYMENT_RATE_CUTOFF = 0.60\n",
    "AVG_INCOME_CUTOFF = 60000\n",
    "\n",
    "# ---------------------Budgeting (By Karthik)----------------------------\n",
    "\n",
    "def compute_populations(pop_df)\n",
    "    df = pop_df.copy()\n",
    "    \n",
    "    # Ensure numeric\n",
    "    for c in df.columns:\n",
    "        if c not in [\"zipcode\", \"ZIP code\", \"zip_code\"]:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "    # Resolve ZIP column name to 'zipcode'\n",
    "    if \"zipcode\" not in df.columns:\n",
    "        if \"ZIP code\" in df.columns:\n",
    "            df.rename(columns={\"ZIP code\": \"zipcode\"}, inplace=True)\n",
    "        elif \"zip_code\" in df.columns:\n",
    "            df.rename(columns={\"zip_code\": \"zipcode\"}, inplace=True)\n",
    "            \n",
    "    # Population bins we need\n",
    "    pop_0_4 = safe_series(df, \"0-4\")\n",
    "    pop_5_9 = safe_series(df, \"5-9\")\n",
    "    pop_10_14 = safe_series(df, \"10-14\")\n",
    "\n",
    "    # Assume the age is uniformly distributed\n",
    "    pop_0_5 = pop_0_4 + (1.0/5.0)*pop_5_9\n",
    "    pop_5_12 = pop_5_9 + (3.0/5.0)*pop_10_14\n",
    "    pop_0_12 = pop_0_5 + pop_5_12\n",
    "    return df[[\"zipcode\"]].assign(pop_0_5=pop_0_5, pop_5_12=pop_5_12, pop_0_12=pop_0_12)\n",
    "\n",
    "'''\n",
    "Budgeting Part: xxxxxxx\n",
    "'''\n",
    "\n",
    "\n",
    "# -------------------Loading and Cleaning Data----------------------\n",
    "def load_data():\n",
    "    \n",
    "    # Child care facilities (existing)\n",
    "    ccare = pd.read_csv(DATA_DIR / \"child_care_regulated.csv\")    \n",
    "    ccare.rename(columns={\"zip_code\": \"zipcode\"}, inplace=True)\n",
    "    # Ensure numeric capacities (fill NaNs with 0)\n",
    "    for col in [\"infant_capacity\", \"toddler_capacity\", \"preschool_capacity\", \"school_age_capacity\", \"children_capacity\", \"total_capacity\"]:\n",
    "        if col in ccare.columns:\n",
    "            ccare[col] = pd.to_numeric(ccare[col], errors=\"coerce\").fillna(0.0)\n",
    "        else:\n",
    "            ccare[col] = 0.0\n",
    "    ccare[\"latitude\"] = pd.to_numeric(ccare[\"latitude\"], errors=\"coerce\")\n",
    "    ccare[\"longitude\"] = pd.to_numeric(ccare[\"longitude\"], errors=\"coerce\")\n",
    "    \n",
    "    # Potential new locations\n",
    "    locs = pd.read_csv(DATA_DIR / \"potential_locations.csv\")\n",
    "\n",
    "    # Population\n",
    "    pop_raw = pd.read_csv(DATA_DIR / \"population.csv\")\n",
    "    pop = compute_populations(pop_raw)\n",
    "    \n",
    "    # Income\n",
    "    inc = pd.read_csv(DATA_DIR / \"avg_individual_income.csv\")\n",
    "    inc.rename(columns={\"ZIP code\": \"zipcode\"}, inplace=True)\n",
    "    inc.rename(columns={\"average income\": \"avg_income\"}, inplace=True)\n",
    "\n",
    "    # Employment rate\n",
    "    emp = pd.read_csv(DATA_DIR / \"employment_rate.csv\")\n",
    "    emp.rename(columns={\"employment rate\": \"employment_rate\"}, inplace=True)\n",
    "\n",
    "    # Merge zip-level data\n",
    "    zip_df = pop.merge(inc[[\"zipcode\", \"avg_income\"]], on=\"zipcode\", how=\"left\") \\\n",
    "                .merge(emp[[\"zipcode\", \"employment_rate\"]], on=\"zipcode\", how=\"left\")\n",
    "    zip_df[\"avg_income\"] = pd.to_numeric(zip_df[\"avg_income\"], errors=\"coerce\")\n",
    "    zip_df[\"employment_rate\"] = pd.to_numeric(zip_df[\"employment_rate\"], errors=\"coerce\")\n",
    "    zip_df.fillna({\"avg_income\": np.inf, \"employment_rate\": 0.0}, inplace=True) \n",
    "\n",
    "    # Pre-aggregate existing capacity per facility and by zip\n",
    "    # Assume that the age 0-5 covers the \"infant_capacity\", \"toddler_capacity\", \"preschool_capacity\"\n",
    "    # Assume that the age 5-12 covers the \"school_age_capacity\"\n",
    "    ccare[\"cap_0_5\"] = ccare[[\"infant_capacity\", \"toddler_capacity\", \"preschool_capacity\"]].sum(axis=1)\n",
    "    ccare[\"cap_5_12\"] = ccare[\"school_age_capacity\"]\n",
    "    ccare[\"cap_total\"] = ccare[\"total_capacity\"].replace({np.nan: 0.0})\n",
    "    \n",
    "    # If total_capacity is missing or zero, fallback to sum of parts\n",
    "    mask_total_zero = (ccare[\"cap_total\"].isna()) | (ccare[\"cap_total\"] <= 0)\n",
    "    ccare.loc[mask_total_zero, \"cap_total\"] = (ccare[\"cap_0_5\"].fillna(0) + ccare[\"cap_5_12\"].fillna(0))\n",
    "\n",
    "    # Facilities with IDs\n",
    "    if \"facility_id\" not in ccare.columns:\n",
    "        ccare[\"facility_id\"] = np.arange(len(ccare))\n",
    "    ccare[\"facility_id\"] = ccare[\"facility_id\"].astype(str)\n",
    "\n",
    "    return ccare, locs, zip_df\n",
    "\n",
    "\n",
    "# --------------------------Modeling - Idealistic Part (By Weiwen)----------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------Modeling - Realistic Part--------------------------------------\n",
    "\n",
    "def build_conflicts(ccare: pd.DataFrame, locs: pd.DataFrame, min_miles=MIN_DISTANCE_MILES):\n",
    "    # Clean coords\n",
    "    locs_clean = locs.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "    ccare_clean = ccare.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "\n",
    "    # Index potential locations within each zip\n",
    "    locs_clean = locs_clean.copy()\n",
    "    locs_clean[\"loc_id\"] = locs_clean.index.astype(int)\n",
    "\n",
    "    new_new_conflicts = {}\n",
    "    new_exist_conflicts = {}\n",
    "\n",
    "    for z, group in locs_clean.groupby(\"zipcode\"):\n",
    "        gps = group[[\"loc_id\", \"latitude\", \"longitude\"]].values.tolist()\n",
    "        pairs = []\n",
    "        for i in range(len(gps)):\n",
    "            for j in range(i+1, len(gps)):\n",
    "                id_i, la_i, lo_i = gps[i]\n",
    "                id_j, la_j, lo_j = gps[j]\n",
    "                d = haversine_miles(la_i, lo_i, la_j, lo_j)\n",
    "                if d < min_miles:\n",
    "                    pairs.append((int(id_i), int(id_j)))\n",
    "        new_new_conflicts[z] = pairs\n",
    "\n",
    "        # new-existing within this zip\n",
    "        exist_pairs = []\n",
    "        ex = ccare_clean[ccare_clean[\"zipcode\"] == z]\n",
    "        for _, r in group.iterrows():\n",
    "            for _, e in ex.iterrows():\n",
    "                d = haversine_miles(r[\"latitude\"], r[\"longitude\"], e[\"latitude\"], e[\"longitude\"])\n",
    "                if d < min_miles:\n",
    "                    exist_pairs.append((int(r[\"loc_id\"]), str(e[\"facility_id\"])))\n",
    "        new_exist_conflicts[z] = exist_pairs\n",
    "\n",
    "    return locs_clean, new_new_conflicts, new_exist_conflicts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "\n",
    "def build_and_solve_model_2(ccare, locs, zip_df, new_new_conflicts, new_exist_conflicts):\n",
    "    m = Model(\"Model_2_Realistic\")\n",
    "\n",
    "    # Indexing sets\n",
    "    F = list(ccare[\"facility_id\"])\n",
    "    facility_nf = dict(zip(F, ccare[\"cap_total\"]))\n",
    "    facility_zip = dict(zip(F, ccare[\"zipcode\"]))\n",
    "\n",
    "    L = list(locs.index)\n",
    "    loc_zip = dict(zip(L, locs[\"zipcode\"]))\n",
    "    Z = list(zip_df[\"zipcode\"])\n",
    "\n",
    "    # Decision variables\n",
    "    # Expansion segments per facility\n",
    "    x1 = {f: m.addVar(lb=0.0, ub=0.10*facility_nf[f], vtype=GRB.CONTINUOUS, name=f\"x1[{f}]\") for f in F}\n",
    "    x2 = {f: m.addVar(lb=0.0, ub=0.05*facility_nf[f], vtype=GRB.CONTINUOUS, name=f\"x2[{f}]\") for f in F}\n",
    "    x3 = {f: m.addVar(lb=0.0, ub=0.05*facility_nf[f], vtype=GRB.CONTINUOUS, name=f\"x3[{f}]\") for f in F}\n",
    "\n",
    "    # New build binary selection\n",
    "    y = {(l, s): m.addVar(vtype=GRB.BINARY, name=f\"y_build[{l},{s}]\") for l in L for s in NEW_FACILITY_SIZES}\n",
    "\n",
    "    # Zip-level allocation variables\n",
    "    s0_5 = {z: m.addVar(lb=0.0, vtype=GRB.CONTINUOUS, name=f\"s0_5[{z}]\") for z in Z}\n",
    "    s5_12 = {z: m.addVar(lb=0.0, vtype=GRB.CONTINUOUS, name=f\"s5_12[{z}]\") for z in Z}\n",
    "    a_new_0_5 = {z: m.addVar(lb=0.0, vtype=GRB.CONTINUOUS, name=f\"a_new0_5[{z}]\") for z in Z}\n",
    "    b_new_5_12 = {z: m.addVar(lb=0.0, vtype=GRB.CONTINUOUS, name=f\"b_new5_12[{z}]\") for z in Z}\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    # Helpers\n",
    "    cap0_5_zip = ccare.groupby(\"zipcode\")[\"cap_0_5\"].sum().to_dict()\n",
    "    cap5_12_zip = ccare.groupby(\"zipcode\")[\"cap_5_12\"].sum().to_dict()\n",
    "    cap_total_zip = ccare.groupby(\"zipcode\")[\"cap_total\"].sum().to_dict()\n",
    "\n",
    "    pop_0_5 = dict(zip(zip_df[\"zipcode\"], zip_df[\"pop_0_5\"]))\n",
    "    pop_5_12 = dict(zip(zip_df[\"zipcode\"], zip_df[\"pop_5_12\"]))\n",
    "    pop_0_12 = dict(zip(zip_df[\"zipcode\"], zip_df[\"pop_0_12\"]))\n",
    "    avg_income = dict(zip(zip_df[\"zipcode\"], zip_df[\"avg_income\"]))\n",
    "    emp_rate = dict(zip(zip_df[\"zipcode\"], zip_df[\"employment_rate\"]))\n",
    "\n",
    "    # Constraints\n",
    "\n",
    "    # Expansion total per facility ≤ 20% nf\n",
    "    for f in F:\n",
    "        nf = facility_nf[f]\n",
    "        m.addConstr(x1[f] + x2[f] + x3[f] <= 0.20 * nf, name=f\"x_total_cap[{f}]\")\n",
    "\n",
    "    # Allocation & policy per zip\n",
    "    for z in Z:\n",
    "        exp_in_z = quicksum(x1[f] + x2[f] + x3[f] for f in F if facility_zip[f] == z)\n",
    "        new_tot_in_z = quicksum(NEW_FACILITY_SIZES[s][\"total\"] * y[l, s] for l in L if loc_zip[l] == z for s in NEW_FACILITY_SIZES)\n",
    "\n",
    "        m.addConstr(s0_5[z] + s5_12[z] == cap_total_zip.get(z, 0.0) + exp_in_z + new_tot_in_z, name=f\"alloc_balance[{z}]\")\n",
    "        m.addConstr(s0_5[z] <= cap0_5_zip.get(z, 0.0) + exp_in_z + a_new_0_5[z], name=f\"max_0_5_bound[{z}]\")\n",
    "        m.addConstr(a_new_0_5[z] <= quicksum(NEW_FACILITY_SIZES[s][\"max_0_5\"] * y[l, s] for l in L if loc_zip[l] == z for s in NEW_FACILITY_SIZES), name=f\"new_0_5_cap[{z}]\")\n",
    "        m.addConstr(a_new_0_5[z] + b_new_5_12[z] <= new_tot_in_z, name=f\"new_split_tot[{z}]\")\n",
    "\n",
    "        high_demand = (emp_rate.get(z, 0.0) >= EMPLOYMENT_RATE_CUTOFF) or (avg_income.get(z, np.inf) <= AVG_INCOME_CUTOFF)\n",
    "        threshold = 0.5 if high_demand else (1.0/3.0)\n",
    "        m.addConstr(s0_5[z] + s5_12[z] >= threshold * pop_0_12.get(z, 0.0), name=f\"desert_off[{z}]\")\n",
    "        m.addConstr(s0_5[z] >= (2.0/3.0)*pop_0_5.get(z, 0.0), name=f\"policy_0_5[{z}]\")\n",
    "\n",
    "    # Distance conflicts within each ZIP\n",
    "    # new-new\n",
    "    for z, pairs in new_new_conflicts.items():\n",
    "        for (i, j) in pairs:\n",
    "            # If any size is built at location i and any size at j, they cannot both be 1 in total.\n",
    "            # Sum across sizes at a location (at most one size per location). We enforce one facility max per location.\n",
    "            m.addConstr(quicksum(y[i, s] for s in NEW_FACILITY_SIZES) + quicksum(y[j, s] for s in NEW_FACILITY_SIZES) <= 1, name=f\"dist_new_new[{z},{i},{j}]\")\n",
    "\n",
    "    # ensure at most one facility per potential location\n",
    "    for l in L:\n",
    "        m.addConstr(quicksum(y[l, s] for s in NEW_FACILITY_SIZES) <= 1, name=f\"one_per_loc[{l}]\")\n",
    "\n",
    "    # new-existing\n",
    "    for z, pairs in new_exist_conflicts.items():\n",
    "        for (i, f) in pairs:\n",
    "            # If location i is too close to existing facility f, then we forbid building at i (within this model).\n",
    "            # This is a conservative modeling choice (you could also allow but add penalty).\n",
    "            m.addConstr(quicksum(y[i, s] for s in NEW_FACILITY_SIZES) <= 0, name=f\"dist_new_exist_block[{z},{i},{f}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
