{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae56cb2a-8858-49bb-bef4-07b436620f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter OutputFlag to value 1\n",
      "Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (mac64[arm] - Darwin 24.5.0 24F74)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 72901 rows, 69544 columns and 307988 nonzeros\n",
      "Model fingerprint: 0x4ea4fb75\n",
      "Variable types: 50376 continuous, 19168 integer (15604 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 9e+02]\n",
      "  Objective range  [1e+02, 2e+05]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e-06, 1e+04]\n",
      "Presolve removed 72864 rows and 69491 columns\n",
      "Presolve time: 1.14s\n",
      "Presolved: 37 rows, 53 columns, 154 nonzeros\n",
      "Variable types: 34 continuous, 19 integer (18 binary)\n",
      "Found heuristic solution: objective 2.880101e+08\n",
      "Found heuristic solution: objective 2.879843e+08\n",
      "\n",
      "Root relaxation: objective 2.879243e+08, 19 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    2.879243e+08 2.8792e+08  0.00%     -    1s\n",
      "\n",
      "Explored 1 nodes (19 simplex iterations) in 1.30 seconds (0.71 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 2.87924e+08 2.87924e+08 2.87984e+08 2.8801e+08 \n",
      "No other solutions better than 2.87924e+08\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Warning: max constraint violation (3.0000e-06) exceeds tolerance\n",
      "Warning: max bound violation (3.9975e-06) exceeds tolerance\n",
      "Best objective 2.879242707385e+08, best bound 2.879242707385e+08, gap 0.0000%\n",
      "\n",
      "=== Objective (USD) === 287,924,270.74\n",
      "Wrote: /Users/windyzhou/Downloads/IEOR4004EProject1/idealistic_solution_by_zip.csv\n",
      "Wrote: /Users/windyzhou/Downloads/IEOR4004EProject1/idealistic_expansion_by_facility.csv\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "\n",
    "# Paths \n",
    "BASE_DIR = os.path.expanduser(\"~/Downloads/IEOR4004EProject1\")\n",
    "PATH_REG = os.path.join(BASE_DIR, \"child_care_regulated.csv\")\n",
    "PATH_POP = os.path.join(BASE_DIR, \"population.csv\")\n",
    "PATH_INC = os.path.join(BASE_DIR, \"avg_individual_income.csv\")\n",
    "PATH_EMP = os.path.join(BASE_DIR, \"employment_rate.csv\")\n",
    "\n",
    "# Policy / cost parameters (idealistic)\n",
    "EXPANSION_COST_PER_SLOT = 250.0           # (legacy flat rate; kept for reference)\n",
    "EQUIP_COST_0_5_PER_SLOT = 100.0           # equipment surcharge per 0–5 slot (new + expanded)\n",
    "NEW_COST   = {\"S\": 65000.0, \"M\": 95000.0, \"L\": 115000.0}\n",
    "NEW_TOTAL  = {\"S\": 100, \"M\": 200, \"L\": 400}\n",
    "NEW_0_5_MAX = {\"S\": 50,  \"M\": 100, \"L\": 200}\n",
    "NEW_5_12_MAX = {k: NEW_TOTAL[k] - NEW_0_5_MAX[k] for k in NEW_TOTAL}\n",
    "\n",
    "# Facility level expansion rule\n",
    "BASELINE_FIXED_IF_100PCT = 20000.0        # fixed part if expand >= 100% at a facility\n",
    "BASELINE_PER_EXISTING    = 200.0          # per existing slot if expand >= 100%\n",
    "MAX_EXP_FRACTION         = 1.20           # up to +120% of existing facility capacity\n",
    "MAX_EXP_SLOTS_PER_FAC    = 500.0          # hard cap per facility\n",
    "BIG_M                    = 500.0          # safe Big-M (matches MAX_EXP_SLOTS_PER_FAC)\n",
    "EPS                      = 1e-6\n",
    "\n",
    "# Load data\n",
    "reg = pd.read_csv(PATH_REG)\n",
    "pop = pd.read_csv(PATH_POP)\n",
    "inc = pd.read_csv(PATH_INC)\n",
    "emp = pd.read_csv(PATH_EMP)\n",
    "\n",
    "# take only the first 5 digits of Zip\n",
    "def _zip_trunc(val):\n",
    "    s = ''.join(ch for ch in str(val) if ch.isdigit())\n",
    "    return np.nan if not s else int(s[:5])\n",
    "\n",
    "reg[\"zipcode\"] = reg[\"zip_code\"].apply(_zip_trunc)\n",
    "pop[\"zipcode\"] = pop[\"zipcode\"].apply(_zip_trunc)\n",
    "inc[\"zipcode\"] = inc[\"ZIP code\"].apply(_zip_trunc)          \n",
    "emp[\"zipcode\"] = emp[\"zipcode\"].apply(_zip_trunc)\n",
    "\n",
    "for d in (reg, pop, inc, emp):\n",
    "    d.dropna(subset=[\"zipcode\"], inplace=True)\n",
    "    d[\"zipcode\"] = d[\"zipcode\"].astype(int)\n",
    "\n",
    "# Aggregate existing capacity by Zip\n",
    "# 0–5 existing = infant + toddler + preschool; older existing = school_age\n",
    "reg[\"cap_0_5\"]  = reg[[\"infant_capacity\",\"toddler_capacity\",\"preschool_capacity\"]].sum(axis=1)\n",
    "reg[\"cap_5_12\"] = reg[[\"school_age_capacity\"]].sum(axis=1)\n",
    "\n",
    "by_zip = (reg.groupby(\"zipcode\")\n",
    "            .agg(cap0_5=(\"cap_0_5\",\"sum\"),\n",
    "                 cap5_12=(\"cap_5_12\",\"sum\"),\n",
    "                 total_cap=(\"total_capacity\",\"sum\"),\n",
    "                 n_facilities=(\"facility_id\",\"count\"))\n",
    "            .reset_index())\n",
    "\n",
    "# Build ZIP table with socio economic & population info\n",
    "df = (by_zip\n",
    "      .merge(pop[[\"zipcode\",\"-5\",\"5-9\",\"10-14\"]], on=\"zipcode\", how=\"left\")\n",
    "      .merge(inc[[\"zipcode\",\"average income\"]],   on=\"zipcode\", how=\"left\")\n",
    "      .merge(emp[[\"zipcode\",\"employment rate\"]],  on=\"zipcode\", how=\"left\"))\n",
    "\n",
    "df[[\"cap0_5\",\"cap5_12\",\"total_cap\"]] = df[[\"cap0_5\",\"cap5_12\",\"total_cap\"]].fillna(0.0)\n",
    "df[\"n_facilities\"] = df[\"n_facilities\"].fillna(0).astype(int)\n",
    "\n",
    "'''Non-overlapping population groups\n",
    "0–5  := (-5) + 1/5*(5–9) (adds 5-year-olds)\n",
    "6–9  := 4/5*(5–9) (ages 6–9)\n",
    "10–12:= 3/5*(10–14) (ages 10–12)'''\n",
    "df[\"pop_0_5\"]   = df[\"-5\"].fillna(0.0) + 0.2 * df[\"5-9\"].fillna(0.0)\n",
    "df[\"pop_6_9\"]   = 0.8 * df[\"5-9\"].fillna(0.0)\n",
    "df[\"pop_10_12\"] = 0.6 * df[\"10-14\"].fillna(0.0)\n",
    "df[\"pop_0_12\"]  = df[\"pop_0_5\"] + df[\"pop_6_9\"] + df[\"pop_10_12\"]\n",
    "\n",
    "# High-demand classification\n",
    "df[\"employment rate\"]   = df[\"employment rate\"].fillna(0.0)\n",
    "df[\"average income\"]    = df[\"average income\"].fillna(1e9)\n",
    "df[\"is_high_demand\"]    = ((df[\"employment rate\"] >= 0.60) | (df[\"average income\"] <= 60000)).astype(int)\n",
    "\n",
    "# Thresholds (strictly above desert line)\n",
    "df[\"threshold_total\"]   = np.where(df[\"is_high_demand\"]==1, 0.50*df[\"pop_0_12\"], (1/3.0)*df[\"pop_0_12\"])\n",
    "df[\"threshold_total\"]   = np.ceil(df[\"threshold_total\"] + 1.0)\n",
    "df[\"threshold_0_5\"]     = np.ceil((2.0/3.0)*df[\"pop_0_5\"])\n",
    "\n",
    "# facility list for expansion decisions\n",
    "fac = reg[[\"facility_id\",\"zipcode\",\"total_capacity\"]].copy()\n",
    "fac = fac.dropna(subset=[\"facility_id\",\"zipcode\"]).copy()\n",
    "fac[\"facility_id\"] = fac[\"facility_id\"].astype(str)\n",
    "fac[\"zipcode\"] = fac[\"zipcode\"].astype(int)\n",
    "fac[\"total_capacity\"] = pd.to_numeric(fac[\"total_capacity\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# Zipcode to list of facility_ids\n",
    "zip_to_facs = fac.groupby(\"zipcode\")[\"facility_id\"].apply(list).to_dict()\n",
    "cap_by_fac  = fac.set_index(\"facility_id\")[\"total_capacity\"].to_dict()\n",
    "\n",
    "'''per-facility tiered expansion rates \n",
    "Assumption:\n",
    "tier S (<=100 existing slots): $100/slot\n",
    "tier M (101..200): $150/slot\n",
    "tier L (>200): $200/slot'''\n",
    "EXP_COST_TIER = {\"S\": 100.0, \"M\": 150.0, \"L\": 200.0}\n",
    "\n",
    "def _tier_from_C(C):\n",
    "    if C <= 100.0:\n",
    "        return \"S\"\n",
    "    elif C <= 200.0:\n",
    "        return \"M\"\n",
    "    else:\n",
    "        return \"L\"\n",
    "\n",
    "exp_cost_fac = {f: EXP_COST_TIER[_tier_from_C(C)] for f, C in cap_by_fac.items()}  # per-facility $/slot\n",
    "\n",
    "# compute deserts pre-intervention\n",
    "df[\"existing_total\"] = df[\"cap0_5\"] + df[\"cap5_12\"]\n",
    "df[\"is_desert_pre\"] = ((df[\"existing_total\"] < df[\"threshold_total\"]) |\n",
    "                       (df[\"cap0_5\"]       < df[\"threshold_0_5\"])).astype(int)\n",
    "desert_zips = set(df.loc[df[\"is_desert_pre\"] == 1, \"zipcode\"].astype(int).tolist())\n",
    "\n",
    "# Gurobi model\n",
    "m = Model(\"IEOR4004E_Idealistic_Gurobi_facility_expansion_desert_only\")\n",
    "\n",
    "# New facility counts \n",
    "yS = {z: m.addVar(vtype=GRB.INTEGER, lb=0, name=f\"yS[{z}]\") for z in df[\"zipcode\"]}\n",
    "yM = {z: m.addVar(vtype=GRB.INTEGER, lb=0, name=f\"yM[{z}]\") for z in df[\"zipcode\"]}\n",
    "yL = {z: m.addVar(vtype=GRB.INTEGER, lb=0, name=f\"yL[{z}]\") for z in df[\"zipcode\"]}\n",
    "\n",
    "# new capacity allocations by age group \n",
    "u_new_0_5  = {z: m.addVar(vtype=GRB.CONTINUOUS, lb=0.0, name=f\"u_new_0_5[{z}]\")  for z in df[\"zipcode\"]}\n",
    "u_new_6_9  = {z: m.addVar(vtype=GRB.CONTINUOUS, lb=0.0, name=f\"u_new_6_9[{z}]\")  for z in df[\"zipcode\"]}\n",
    "u_new_10_12= {z: m.addVar(vtype=GRB.CONTINUOUS, lb=0.0, name=f\"u_new_10_12[{z}]\") for z in df[\"zipcode\"]}\n",
    "\n",
    "# facility level expansion variables by age group\n",
    "eF_0_5   = {f: m.addVar(vtype=GRB.CONTINUOUS, lb=0.0, name=f\"eF_0_5[{f}]\")   for f in cap_by_fac}\n",
    "eF_6_9   = {f: m.addVar(vtype=GRB.CONTINUOUS, lb=0.0, name=f\"eF_6_9[{f}]\")   for f in cap_by_fac}\n",
    "eF_10_12 = {f: m.addVar(vtype=GRB.CONTINUOUS, lb=0.0, name=f\"eF_10_12[{f}]\") for f in cap_by_fac}\n",
    "# expansion >= 100% at facility f?\n",
    "yF_100p  = {f: m.addVar(vtype=GRB.BINARY, name=f\"yF_100p[{f}]\")               for f in cap_by_fac}\n",
    "\n",
    "m.update()\n",
    "\n",
    "def total_new(z):     return NEW_TOTAL[\"S\"]*yS[z] + NEW_TOTAL[\"M\"]*yM[z] + NEW_TOTAL[\"L\"]*yL[z]\n",
    "def max_new_0_5(z):   return NEW_0_5_MAX[\"S\"]*yS[z] + NEW_0_5_MAX[\"M\"]*yM[z] + NEW_0_5_MAX[\"L\"]*yL[z]\n",
    "def max_new_5_12(z):  return NEW_5_12_MAX[\"S\"]*yS[z] + NEW_5_12_MAX[\"M\"]*yM[z] + NEW_5_12_MAX[\"L\"]*yL[z]\n",
    "\n",
    "# Facility level expansion limits and trigger\n",
    "for f, C_f in cap_by_fac.items():\n",
    "    E_f = eF_0_5[f] + eF_6_9[f] + eF_10_12[f]\n",
    "    m.addConstr(E_f <= MAX_EXP_FRACTION * C_f, name=f\"exp_frac_cap[{f}]\")\n",
    "    m.addConstr(E_f <= MAX_EXP_SLOTS_PER_FAC,  name=f\"exp_abs_cap[{f}]\")\n",
    "    # Trigger yF_100p = 1 iff E_f >= C_f\n",
    "    m.addConstr(E_f - C_f * yF_100p[f] >= 0.0,                   name=f\"trigger_lb[{f}]\")\n",
    "    m.addConstr(E_f <= (C_f - EPS) + BIG_M * yF_100p[f],         name=f\"trigger_ub[{f}]\")\n",
    "\n",
    "# ZIP-level coverage and deserts-only investment \n",
    "dfi = df.set_index(\"zipcode\")\n",
    "\n",
    "for z, r in dfi.iterrows():\n",
    "    facs = zip_to_facs.get(int(z), [])\n",
    "    sum_e0_5   = quicksum(eF_0_5[f]   for f in facs)\n",
    "    sum_e6_9   = quicksum(eF_6_9[f]   for f in facs)\n",
    "    sum_e10_12 = quicksum(eF_10_12[f] for f in facs)\n",
    "\n",
    "    total_after_0_5  = r[\"cap0_5\"]  + sum_e0_5 + u_new_0_5[z]\n",
    "    total_after_older= r[\"cap5_12\"] + (sum_e6_9 + sum_e10_12) + (u_new_6_9[z] + u_new_10_12[z])\n",
    "    total_after      = total_after_0_5 + total_after_older\n",
    "\n",
    "    # Coverage constraints\n",
    "    m.addConstr(total_after     >= r[\"threshold_total\"], name=f\"not_desert[{z}]\")\n",
    "    m.addConstr(total_after_0_5 >= r[\"threshold_0_5\"],  name=f\"u05_policy[{z}]\")\n",
    "\n",
    "    # New build allocation envelopes\n",
    "    m.addConstr(u_new_0_5[z]                  <= max_new_0_5(z),  name=f\"new_0_5_cap[{z}]\")\n",
    "    m.addConstr(u_new_6_9[z] + u_new_10_12[z] <= max_new_5_12(z), name=f\"new_older_cap[{z}]\")\n",
    "    m.addConstr(u_new_0_5[z] + u_new_6_9[z] + u_new_10_12[z] == total_new(z), name=f\"new_alloc_bal[{z}]\")\n",
    "\n",
    "    # Deserts-only investment\n",
    "    if int(r[\"is_desert_pre\"]) == 0:\n",
    "        m.addConstr(yS[z] == 0, name=f\"no_build_S_non_desert[{z}]\")\n",
    "        m.addConstr(yM[z] == 0, name=f\"no_build_M_non_desert[{z}]\")\n",
    "        m.addConstr(yL[z] == 0, name=f\"no_build_L_non_desert[{z}]\")\n",
    "        m.addConstr(u_new_0_5[z] == 0,   name=f\"no_new_0_5_non_desert[{z}]\")\n",
    "        m.addConstr(u_new_6_9[z] == 0,   name=f\"no_new_6_9_non_desert[{z}]\")\n",
    "        m.addConstr(u_new_10_12[z] == 0, name=f\"no_new_10_12_non_desert[{z}]\")\n",
    "        for f in facs:\n",
    "            m.addConstr(eF_0_5[f]   == 0, name=f\"no_exp_0_5_non_desert[{f}]\")\n",
    "            m.addConstr(eF_6_9[f]   == 0, name=f\"no_exp_6_9_non_desert[{f}]\")\n",
    "            m.addConstr(eF_10_12[f] == 0, name=f\"no_exp_10_12_non_desert[{f}]\")\n",
    "\n",
    "# build + equipment(0–5) + per-slot expansion + baseline if >=100% \n",
    "build_cost  = quicksum(NEW_COST[\"S\"]*yS[z] + NEW_COST[\"M\"]*yM[z] + NEW_COST[\"L\"]*yL[z] for z in dfi.index)\n",
    "equip_cost  = quicksum(EQUIP_COST_0_5_PER_SLOT * (u_new_0_5[z]) for z in dfi.index) \\\n",
    "            + quicksum(EQUIP_COST_0_5_PER_SLOT * (eF_0_5[f])    for f in cap_by_fac)\n",
    "\n",
    "# flat version, not used in this code but kept in case it's needed for debugging:\n",
    "expand_slots = quicksum(eF_0_5[f] + eF_6_9[f] + eF_10_12[f] for f in cap_by_fac)\n",
    "\n",
    "# tiered per-slot expansion cost by facility size\n",
    "expand_cost = quicksum(\n",
    "    exp_cost_fac[f] * (eF_0_5[f] + eF_6_9[f] + eF_10_12[f])\n",
    "    for f in cap_by_fac\n",
    ")\n",
    "\n",
    "baseline_cost = quicksum(\n",
    "    (BASELINE_FIXED_IF_100PCT + BASELINE_PER_EXISTING * cap_by_fac[f]) * yF_100p[f]\n",
    "    for f in cap_by_fac\n",
    ")\n",
    "\n",
    "m.setObjective(build_cost + equip_cost + expand_cost + baseline_cost, GRB.MINIMIZE)\n",
    "\n",
    "m.Params.OutputFlag = 1\n",
    "m.optimize()\n",
    "\n",
    "# Collect, save results\n",
    "rows = []\n",
    "for z, r in dfi.iterrows():\n",
    "    y_s, y_m, y_l = int(round(yS[z].X)), int(round(yM[z].X)), int(round(yL[z].X))\n",
    "    new_total = NEW_TOTAL[\"S\"]*y_s + NEW_TOTAL[\"M\"]*y_m + NEW_TOTAL[\"L\"]*y_l\n",
    "\n",
    "    facs = zip_to_facs.get(int(z), [])\n",
    "    sum_e0_5   = sum(eF_0_5[f].X   for f in facs)\n",
    "    sum_e6_9   = sum(eF_6_9[f].X   for f in facs)\n",
    "    sum_e10_12 = sum(eF_10_12[f].X for f in facs)\n",
    "\n",
    "    rows.append(dict(\n",
    "        zipcode=int(z),\n",
    "        is_high_demand=int(r[\"is_high_demand\"]),\n",
    "        is_desert_pre=int(r[\"is_desert_pre\"]),\n",
    "        pop_0_5=float(r[\"pop_0_5\"]), pop_6_9=float(r[\"pop_6_9\"]), pop_10_12=float(r[\"pop_10_12\"]),\n",
    "        pop_0_12=float(r[\"pop_0_12\"]),\n",
    "        threshold_total=float(r[\"threshold_total\"]), threshold_0_5=float(r[\"threshold_0_5\"]),\n",
    "        existing_cap_total=float(r[\"existing_total\"]),\n",
    "        existing_cap_0_5=float(r[\"cap0_5\"]),\n",
    "        existing_cap_5_12=float(r[\"cap5_12\"]),\n",
    "        y_small=y_s, y_medium=y_m, y_large=y_l,\n",
    "        u_new_0_5=float(u_new_0_5[z].X),\n",
    "        u_new_6_9=float(u_new_6_9[z].X),\n",
    "        u_new_10_12=float(u_new_10_12[z].X),\n",
    "        e_0_5=float(sum_e0_5),\n",
    "        e_6_9=float(sum_e6_9),\n",
    "        e_10_12=float(sum_e10_12),\n",
    "        new_total_slots=float(new_total)\n",
    "    ))\n",
    "\n",
    "# Facility-level audit\n",
    "fac_rows = []\n",
    "for f, C_f in cap_by_fac.items():\n",
    "    zf = int(fac.loc[fac[\"facility_id\"]==f, \"zipcode\"].iloc[0])\n",
    "    fac_rows.append(dict(\n",
    "        facility_id=f,\n",
    "        zipcode=zf,\n",
    "        existing_total=float(C_f),\n",
    "        exp_rate_per_slot=float(exp_cost_fac[f]),  # UPDATED: report rate used\n",
    "        exp_0_5=float(eF_0_5[f].X),\n",
    "        exp_6_9=float(eF_6_9[f].X),\n",
    "        exp_10_12=float(eF_10_12[f].X),\n",
    "        expanded_slots=float(eF_0_5[f].X + eF_6_9[f].X + eF_10_12[f].X),\n",
    "        triggered_baseline=int(round(yF_100p[f].X))\n",
    "    ))\n",
    "\n",
    "zip_df = pd.DataFrame(rows).sort_values(\"zipcode\")\n",
    "fac_df = pd.DataFrame(fac_rows).sort_values([\"zipcode\",\"facility_id\"])\n",
    "\n",
    "OUT1 = os.path.join(BASE_DIR, \"idealistic_solution_by_zip.csv\")\n",
    "OUT2 = os.path.join(BASE_DIR, \"idealistic_expansion_by_facility.csv\")\n",
    "zip_df.to_csv(OUT1, index=False)\n",
    "fac_df.to_csv(OUT2, index=False)\n",
    "print(\"\\n=== Objective (USD) ===\", f\"{m.objVal:,.2f}\")\n",
    "print(\"Wrote:\", OUT1)\n",
    "print(\"Wrote:\", OUT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec18bb57-8408-47a0-b3a3-fa2aa00079d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ZIP codes: 1188\n",
      "Childcare deserts: 888 (74.75%)\n",
      "\n",
      "✅ CSV file saved to: /Users/windyzhou/Downloads/childcare_desert_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compute desert flag based on threshold\n",
    "df[\"is_desert\"] = (df[\"total_cap\"] < df[\"threshold_total\"]).astype(int)\n",
    "\n",
    "# Step 2: Select and rename columns for clarity\n",
    "summary = df[[\n",
    "    \"zipcode\",\n",
    "    \"pop_0_5\", \"pop_0_12\",\n",
    "    \"employment rate\", \"average income\",\n",
    "    \"cap0_5\", \"total_cap\",\n",
    "    \"is_high_demand\",\n",
    "    \"threshold_total\", \"threshold_0_5\",\n",
    "    \"is_desert\"\n",
    "]].copy()\n",
    "\n",
    "summary.rename(columns={\n",
    "    \"pop_0_5\": \"children_0_5\",\n",
    "    \"pop_0_12\": \"children_0_12\",\n",
    "    \"cap0_5\": \"existing_slots_0_5\",\n",
    "    \"total_cap\": \"existing_slots_total\",\n",
    "    \"employment rate\": \"employment_rate\",\n",
    "    \"average income\": \"average_income\",\n",
    "    \"is_high_demand\": \"high_demand\",\n",
    "    \"threshold_total\": \"required_total_slots\",\n",
    "    \"threshold_0_5\": \"required_under5_slots\",\n",
    "    \"is_desert\": \"is_desert_area\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 3: Optional — add summary statistics\n",
    "num_deserts = summary[\"is_desert_area\"].sum()\n",
    "total_zipcodes = len(summary)\n",
    "print(f\"Total ZIP codes: {total_zipcodes}\")\n",
    "print(f\"Childcare deserts: {num_deserts} ({num_deserts / total_zipcodes:.2%})\")\n",
    "\n",
    "# Step 4: Save CSV to Downloads folder\n",
    "output_path = os.path.expanduser(\"~/Downloads/childcare_desert_summary.csv\")\n",
    "summary.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ CSV file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4690c2-c42c-480d-9c5b-0034c746f703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Summary file saved to: /Users/windyzhou/Downloads/IEOR4004EProject1/idealistic_summary_by_ziplalal.csv\n",
      "Total ZIPs: 1188 | Avg new slots per ZIP: 807.6\n"
     ]
    }
   ],
   "source": [
    "summary_rows = []\n",
    "\n",
    "for z, r in dfi.iterrows():\n",
    "    # New builds\n",
    "    y_s, y_m, y_l = int(round(yS[z].X)), int(round(yM[z].X)), int(round(yL[z].X))\n",
    "    new_slots = (\n",
    "        NEW_TOTAL[\"S\"] * y_s +\n",
    "        NEW_TOTAL[\"M\"] * y_m +\n",
    "        NEW_TOTAL[\"L\"] * y_l\n",
    "    )\n",
    "\n",
    "    # Expansions at facilities in this ZIP\n",
    "    facs = zip_to_facs.get(int(z), [])\n",
    "    exp_0_5 = sum(eF_0_5[f].X for f in facs)\n",
    "    exp_6_9 = sum(eF_6_9[f].X for f in facs)\n",
    "    exp_10_12 = sum(eF_10_12[f].X for f in facs)\n",
    "    exp_total = exp_0_5 + exp_6_9 + exp_10_12\n",
    "\n",
    "    # Combined new + expanded\n",
    "    total_added_0_5 = r[\"cap0_5\"] + exp_0_5 + u_new_0_5[z].X\n",
    "    total_added_all = r[\"total_cap\"] + exp_total + new_slots\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"zipcode\": int(z),\n",
    "        \"is_high_demand\": int(r[\"is_high_demand\"]),\n",
    "        \"existing_slots_total\": float(r[\"total_cap\"]),\n",
    "        \"existing_slots_0_5\": float(r[\"cap0_5\"]),\n",
    "        \"expanded_slots_total\": float(exp_total),\n",
    "        \"expanded_slots_0_5\": float(exp_0_5),\n",
    "        \"new_build_small\": y_s,\n",
    "        \"new_build_medium\": y_m,\n",
    "        \"new_build_large\": y_l,\n",
    "        \"new_slots_total\": float(new_slots),\n",
    "        \"total_added_slots_total\": float(exp_total + new_slots),\n",
    "        \"total_added_slots_0_5\": float(exp_0_5 + u_new_0_5[z].X),\n",
    "        \"final_total_slots\": float(total_added_all),\n",
    "        \"threshold_total\": float(r[\"threshold_total\"]),\n",
    "        \"threshold_0_5\": float(r[\"threshold_0_5\"]),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"zipcode\")\n",
    "\n",
    "# === Save to CSV ===\n",
    "OUT_SUM = os.path.join(BASE_DIR, \"idealistic_summary_by_ziplalal.csv\")\n",
    "summary_df.to_csv(OUT_SUM, index=False)\n",
    "\n",
    "print(f\"\\n✅ Summary file saved to: {OUT_SUM}\")\n",
    "print(f\"Total ZIPs: {len(summary_df)} | Avg new slots per ZIP: {summary_df['total_added_slots_total'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d0283b2-2969-43d9-87b7-576797cb7f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'e_5_9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'e_5_9'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_added\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_total_slots\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me_0_5\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me_5_9\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me_9_12\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas_desert_before\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting_cap_total\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold_total\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      3\u001b[0m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas_desert_after\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;241m=\u001b[39m (zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting_cap_total\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_added\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m zip_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold_total\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'e_5_9'"
     ]
    }
   ],
   "source": [
    "zip_df[\"total_added\"] = zip_df[\"new_total_slots\"] + zip_df[\"e_0_5\"] + zip_df[\"e_5_9\"] + zip_df[\"e_9_12\"]\n",
    "zip_df[\"was_desert_before\"] = (zip_df[\"existing_cap_total\"] < zip_df[\"threshold_total\"]).astype(int)\n",
    "zip_df[\"was_desert_after\"]  = (zip_df[\"existing_cap_total\"] + zip_df[\"total_added\"] < zip_df[\"threshold_total\"]).astype(int)\n",
    "\n",
    "print(zip_df.groupby(\"was_desert_before\")[[\"total_added\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa43be4-7107-4b2a-9dfb-ad46c4b5fe49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
